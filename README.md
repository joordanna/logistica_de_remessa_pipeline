# Logistics Analytics Project

## Análise de dados logísticos com Python, SQL Server e Data Cleaning

Este projeto tem como objetivo analisar um conjunto de dados logísticos contendo informações sobre origem, destino, peso, tarifas, prazos e demais características relacionadas ao envio de mercadorias.
O foco do projeto é transformar dados brutos em insights úteis, passando por etapas de limpeza, padronização, integração com banco de dados e consultas SQL.

# Tecnologias Utilizadas

 - Python (Pandas) — limpeza e padronização dos dados

 - SQL Server — criação do banco e execução das consultas

 - Jupyter Notebook — manipulação e integração dos dados

 - GitHub — versionamento e documentação

# Estrutura do Projeto

 - data_cleaning.ipynb — tratamento do CSV original

 - df_refinado.csv — dataset limpo e padronizado

 - sql_queries.sql — consultas utilizadas no projeto

 - README.md — documentação do projeto

# Principais Análises Realizadas

 - Contagem total de registros

 - Top 10 cidades de origem

 - Top 10 cidades de destino

 - Tarifa média por cidade

 - Total de VAS Charges por destino

 - Análise de prazos (Receive_Date vs Expiry_Date)

 - Distribuição dos modos de pagamento

# Insights Identificados

 - 4 cidades aparecem simultaneamente entre as que mais enviam e mais recebem remessas (Patna, Mumbai, Vijayawada e Pune).

 - Cartão é o método de pagamento mais comum.

 - Tarifas e VAS Charges apresentam variações importantes entre regiões.

# Banco de Dados

 Database: LogisticsDB2
 Tabela: LogisticsTable
 Criada com base no schema refinado após o tratamento do CSV.

# Objetivo do Projeto

  Demonstrar domínio do ciclo completo de dados:
  coleta → limpeza → modelagem → carregamento → análise → insights.

### Caso queira trocar ideias sobre análise de dados, SQL ou portfólio:
  LinkedIn: [(https://www.linkedin.com/in/jordana-andrade-1669292a5/)]
